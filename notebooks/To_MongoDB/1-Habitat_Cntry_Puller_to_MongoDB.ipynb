{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies for Selenium\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Module used to connect Python to MongoDB\n",
    "import pymongo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies -cont'd\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependency -cont'd\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read animal web ID for urls on www.iucnredlist.org and convert it to Pandas DataFrame\n",
    "animal_df = pd.read_csv('../../data/animal_iucn_webid.csv', encoding='UTF-8')\n",
    "\n",
    "# Preview \"animal_df\"\n",
    "animal_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup connection to MongoDB using default port 27017\n",
    "conn = 'mongodb://localhost:27017'\n",
    "client = pymongo.MongoClient(conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establish \"EndangeredAnimalDB\" Database and \"animal_facts\" Collection\n",
    "db = client.EndangeredAnimalDB\n",
    "coll = db.animal_facts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic url\n",
    "basic_url = 'https://www.iucnredlist.org/species/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through animals in \"animal_df\"\n",
    "for i in range(len(animal_df)):\n",
    "    \n",
    "    # Time intervals between two adjacent query\n",
    "    time.sleep(1.5)\n",
    "    \n",
    "    # Generating complete url by concatenating basic url with animal web ID\n",
    "    url = basic_url + animal_df['IUCN_WebID'][i]    \n",
    "\n",
    "    # Use selenium in Chrome\n",
    "    driver = webdriver.Chrome(executable_path=r\"../chromedriver.exe\")\n",
    "    \n",
    "    # Get url of the iterated webpage\n",
    "    driver.get(url)\n",
    "\n",
    "    try:\n",
    "        # Use WebDriverWait in combination with ExpectedCondition to setup implicit wait\n",
    "        # In this case, it is 10 sec for id=\"geographic-range\" to respond to calls before sending Exception message\n",
    "        element = WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_element_located((By.ID, \"geographic-range\"))\n",
    "        )\n",
    "        \n",
    "        # Pass iterated animal name to \"dict_im\"\n",
    "        dict_im = {'Common_Name': animal_df['Common_Name'][i]}\n",
    "        \n",
    "        # Retrieve all 'h4' and 'p' elements under \"<div class='u--margin-top-sm'>\" as located by xpath\n",
    "        for j in range(1, 3):            \n",
    "            for k in range(2, 7):\n",
    "                \n",
    "                try:\n",
    "                    # Retrieve 'h4' element during each iteration\n",
    "                    h4_query = driver.find_elements_by_xpath(f\"//*[@id='geographic-range']/div[1]/div[{str(j)}]/div/div[{str(k)}]/h4\")\n",
    "                    # Retrieve 'p' element during each iteration\n",
    "                    p_query = driver.find_elements_by_xpath(f\"//*[@id='geographic-range']/div[1]/div[{str(j)}]/div/div[{str(k)}]/p\")                             \n",
    "                    \n",
    "                    # Retrieve text of 'h4' element\n",
    "                    h4_split_list = h4_query[0].text.split(\" \")\n",
    "\n",
    "                    # Look for 'h4' element text starting with \"Extant\"\n",
    "                    if h4_split_list[0] == \"Extant\":\n",
    "\n",
    "                        # Convert the query result to country-containing list\n",
    "                        cntries = p_query[0].text.split(\";\")\n",
    "\n",
    "                        # Remove space appearing in front of country name starting from the second one in the list\n",
    "                        for l in range(1, len(cntries)):\n",
    "                            cntries[l] = cntries[l][1:]\n",
    "\n",
    "                        # Add result in \"dict_im\"\n",
    "                        dict_im[h4_query[0].text] = cntries\n",
    "                        \n",
    "                except IndexError:\n",
    "                    pass\n",
    "                \n",
    "        # Save document into MongoDB \n",
    "        coll.insert_one(dict_im)\n",
    "\n",
    "    except:\n",
    "        raise Exception('Timed out. Cannot find it..')\n",
    "\n",
    "    # Clear the driver after scraping of the iterated animal\n",
    "    driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
